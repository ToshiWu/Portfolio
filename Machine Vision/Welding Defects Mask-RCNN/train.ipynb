{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import yaml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    " \n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  384\n",
      "IMAGE_META_SIZE                19\n",
      "IMAGE_MIN_DIM                  320\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [384 384   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           Welding\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (48, 96, 192, 384, 768)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           100\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "label_classes                  6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WeldingConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"Welding\"\n",
    "    label_classes = 6\n",
    " \n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    " \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + label_classes  # background + 1 shapes\n",
    " \n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 320\n",
    "    IMAGE_MAX_DIM = 384\n",
    " \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8 * 6, 16 * 6, 32 * 6, 64 * 6, 128 * 6)  # anchor side in pixels\n",
    " \n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 100\n",
    " \n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    " \n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 50\n",
    " \n",
    " \n",
    "config = WeldingConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeldingDataset(utils.Dataset):\n",
    "    def get_obj_index(self, image):\n",
    "        n = np.max(image)\n",
    "        return n\n",
    " \n",
    "    def from_yaml_get_class(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        with open(info['yaml_path']) as f:\n",
    "            temp = yaml.load(f.read())\n",
    "            labels = temp['label_names']\n",
    "            del labels[0]\n",
    "        return labels\n",
    " \n",
    "    def draw_mask(self, num_obj, mask, image, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        for index in range(num_obj):\n",
    "            for i in range(info['width']):\n",
    "                for j in range(info['height']):\n",
    "                    at_pixel = image.getpixel((i, j))\n",
    "                    if at_pixel == index + 1:\n",
    "                        mask[j, i, index] = 1\n",
    "        return mask\n",
    " \n",
    "    def load_img(self, count, img_floder, mask_floder, imglist, dataset_root_path):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        class_list=['air hole', 'pit hole', 'shifted', 'joint', 'decay', 'standard']\n",
    "        for i,x in enumerate(class_list):\n",
    "            self.add_class(\"welding\", i+1, x)\n",
    " \n",
    "        for i in range(count):\n",
    "            filestr = imglist[i].split(\".\")[0]\n",
    "            mask_path = mask_floder + \"/\" + filestr + \".png\"\n",
    "            yaml_path = dataset_root_path + \"labelme_json/\" + filestr + \"_json/info.yaml\"\n",
    "            cv_img = cv2.imread(dataset_root_path + \"labelme_json/\" + filestr + \"_json/img.png\")\n",
    "            self.add_image(\"welding\", image_id=i, path=img_floder + \"/\" + imglist[i],\n",
    "                           width=cv_img.shape[1], height=cv_img.shape[0], mask_path=mask_path, yaml_path=yaml_path)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        count = 1  # number of object\n",
    "        img = Image.open(info['mask_path'])\n",
    "        num_obj = self.get_obj_index(img)\n",
    "        mask = np.zeros([info['height'], info['width'], num_obj], dtype=np.uint8)\n",
    "        mask = self.draw_mask(num_obj, mask, img, image_id)\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        labels = self.from_yaml_get_class(image_id)\n",
    "        class_ids = np.array([self.class_names.index(s) for s in labels])\n",
    "        return mask, class_ids.astype(np.int32)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setpath(root_path):\n",
    "    img_floder = root_path + \"pic\"\n",
    "    mask_floder = root_path + \"cv2_mask\"\n",
    "    imglist = os.listdir(img_floder)\n",
    "    count = len(imglist)\n",
    "    return count, img_floder, mask_floder, imglist, root_path\n",
    "\n",
    "dataset_train = WeldingDataset()\n",
    "dataset_train.load_img(*setpath(\"./train_data/\"))\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = WeldingDataset()\n",
    "dataset_val.load_img(*setpath(\"./val_data/\"))\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_weights(model, init_with, COCO_MODEL_PATH = COCO_MODEL_PATH):\n",
    "    # imagenet, coco, or last\n",
    "    if init_with == \"imagenet\":\n",
    "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    # print(COCO_MODEL_PATH)\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "        model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 225s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 2.4936 - rpn_class_loss: 0.1998 - rpn_bbox_loss: 1.2610 - mrcnn_class_loss: 0.1789 - mrcnn_bbox_loss: 0.5021 - mrcnn_mask_loss: 0.3518 - val_loss: 1.8393 - val_rpn_class_loss: 0.0766 - val_rpn_bbox_loss: 1.2349 - val_mrcnn_class_loss: 0.0648 - val_mrcnn_bbox_loss: 0.2400 - val_mrcnn_mask_loss: 0.2230\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 215s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 1.6458 - rpn_class_loss: 0.0469 - rpn_bbox_loss: 0.7137 - mrcnn_class_loss: 0.1349 - mrcnn_bbox_loss: 0.4440 - mrcnn_mask_loss: 0.3063 - val_loss: 1.4466 - val_rpn_class_loss: 0.0839 - val_rpn_bbox_loss: 0.6480 - val_mrcnn_class_loss: 0.1515 - val_mrcnn_bbox_loss: 0.2847 - val_mrcnn_mask_loss: 0.2785\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 249s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 1.3425 - rpn_class_loss: 0.0459 - rpn_bbox_loss: 0.6076 - mrcnn_class_loss: 0.1142 - mrcnn_bbox_loss: 0.3518 - mrcnn_mask_loss: 0.2229 - val_loss: 1.5984 - val_rpn_class_loss: 0.0530 - val_rpn_bbox_loss: 0.8658 - val_mrcnn_class_loss: 0.0972 - val_mrcnn_bbox_loss: 0.3079 - val_mrcnn_mask_loss: 0.2746\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 234s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 1.1501 - rpn_class_loss: 0.0299 - rpn_bbox_loss: 0.4900 - mrcnn_class_loss: 0.0742 - mrcnn_bbox_loss: 0.3402 - mrcnn_mask_loss: 0.2158 - val_loss: 1.2397 - val_rpn_class_loss: 0.0277 - val_rpn_bbox_loss: 0.5501 - val_mrcnn_class_loss: 0.0907 - val_mrcnn_bbox_loss: 0.3589 - val_mrcnn_mask_loss: 0.2122\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 217s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.8005 - rpn_class_loss: 0.0211 - rpn_bbox_loss: 0.2728 - mrcnn_class_loss: 0.0651 - mrcnn_bbox_loss: 0.2516 - mrcnn_mask_loss: 0.1899 - val_loss: 1.0509 - val_rpn_class_loss: 0.0389 - val_rpn_bbox_loss: 0.5473 - val_mrcnn_class_loss: 0.0606 - val_mrcnn_bbox_loss: 0.1906 - val_mrcnn_mask_loss: 0.2137\n",
      "\n",
      "Starting at epoch 5. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 223s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 2.0674 - rpn_class_loss: 0.0389 - rpn_bbox_loss: 0.5465 - mrcnn_class_loss: 0.0580 - mrcnn_bbox_loss: 0.2174 - mrcnn_mask_loss: 0.1730 - val_loss: 3.2154 - val_rpn_class_loss: 0.0909 - val_rpn_bbox_loss: 1.1050 - val_mrcnn_class_loss: 0.0658 - val_mrcnn_bbox_loss: 0.1500 - val_mrcnn_mask_loss: 0.1960\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 214s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 2.1380 - rpn_class_loss: 0.0373 - rpn_bbox_loss: 0.6139 - mrcnn_class_loss: 0.0523 - mrcnn_bbox_loss: 0.2047 - mrcnn_mask_loss: 0.1607 - val_loss: 2.5645 - val_rpn_class_loss: 0.0570 - val_rpn_bbox_loss: 0.8041 - val_mrcnn_class_loss: 0.0605 - val_mrcnn_bbox_loss: 0.1661 - val_mrcnn_mask_loss: 0.1945\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 210s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 1.7405 - rpn_class_loss: 0.0368 - rpn_bbox_loss: 0.4608 - mrcnn_class_loss: 0.0507 - mrcnn_bbox_loss: 0.1927 - mrcnn_mask_loss: 0.1293 - val_loss: 2.1013 - val_rpn_class_loss: 0.0225 - val_rpn_bbox_loss: 0.5466 - val_mrcnn_class_loss: 0.0761 - val_mrcnn_bbox_loss: 0.1741 - val_mrcnn_mask_loss: 0.2314\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 220s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 1.5428 - rpn_class_loss: 0.0218 - rpn_bbox_loss: 0.3802 - mrcnn_class_loss: 0.0424 - mrcnn_bbox_loss: 0.1982 - mrcnn_mask_loss: 0.1288 - val_loss: 2.1538 - val_rpn_class_loss: 0.0613 - val_rpn_bbox_loss: 0.5326 - val_mrcnn_class_loss: 0.0934 - val_mrcnn_bbox_loss: 0.1919 - val_mrcnn_mask_loss: 0.1978\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 251s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 1.3808 - rpn_class_loss: 0.0218 - rpn_bbox_loss: 0.3565 - mrcnn_class_loss: 0.0266 - mrcnn_bbox_loss: 0.1654 - mrcnn_mask_loss: 0.1202 - val_loss: 2.6285 - val_rpn_class_loss: 0.0445 - val_rpn_bbox_loss: 0.4681 - val_mrcnn_class_loss: 0.2227 - val_mrcnn_bbox_loss: 0.1805 - val_mrcnn_mask_loss: 0.3985\n",
      "\n",
      "Starting at epoch 10. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 276s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 5.0349 - rpn_class_loss: 0.1519 - rpn_bbox_loss: 1.0583 - mrcnn_class_loss: 0.1199 - mrcnn_bbox_loss: 0.1775 - mrcnn_mask_loss: 0.1707 - val_loss: 5.0262 - val_rpn_class_loss: 0.1037 - val_rpn_bbox_loss: 0.8187 - val_mrcnn_class_loss: 0.3112 - val_mrcnn_bbox_loss: 0.2158 - val_mrcnn_mask_loss: 0.2260\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 254s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 3.9538 - rpn_class_loss: 0.0983 - rpn_bbox_loss: 0.7868 - mrcnn_class_loss: 0.1030 - mrcnn_bbox_loss: 0.1805 - mrcnn_mask_loss: 0.1494 - val_loss: 5.3525 - val_rpn_class_loss: 0.1346 - val_rpn_bbox_loss: 1.1624 - val_mrcnn_class_loss: 0.0460 - val_mrcnn_bbox_loss: 0.2197 - val_mrcnn_mask_loss: 0.2216\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 253s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 4.3569 - rpn_class_loss: 0.1371 - rpn_bbox_loss: 0.9191 - mrcnn_class_loss: 0.0766 - mrcnn_bbox_loss: 0.1740 - mrcnn_mask_loss: 0.1454 - val_loss: 5.4254 - val_rpn_class_loss: 0.1018 - val_rpn_bbox_loss: 1.2218 - val_mrcnn_class_loss: 0.0978 - val_mrcnn_bbox_loss: 0.1522 - val_mrcnn_mask_loss: 0.2349\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 292s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 2.5734 - rpn_class_loss: 0.0576 - rpn_bbox_loss: 0.4651 - mrcnn_class_loss: 0.0533 - mrcnn_bbox_loss: 0.1575 - mrcnn_mask_loss: 0.1242 - val_loss: 2.5278 - val_rpn_class_loss: 0.0327 - val_rpn_bbox_loss: 0.4578 - val_mrcnn_class_loss: 0.0517 - val_mrcnn_bbox_loss: 0.1447 - val_mrcnn_mask_loss: 0.1557\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 280s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 3.0536 - rpn_class_loss: 0.0636 - rpn_bbox_loss: 0.6789 - mrcnn_class_loss: 0.0350 - mrcnn_bbox_loss: 0.1270 - mrcnn_mask_loss: 0.1133 - val_loss: 3.4526 - val_rpn_class_loss: 0.0376 - val_rpn_bbox_loss: 0.5622 - val_mrcnn_class_loss: 0.0868 - val_mrcnn_bbox_loss: 0.2056 - val_mrcnn_mask_loss: 0.2588\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "load_weights(model, \"coco\", COCO_MODEL_PATH) \n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=5,\n",
    "            layers='heads')\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=10,\n",
    "            layers='5+')\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=15,\n",
    "            layers='3+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 15. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 322s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 1.1253 - rpn_class_loss: 0.0736 - rpn_bbox_loss: 0.7226 - mrcnn_class_loss: 0.0588 - mrcnn_bbox_loss: 0.1509 - mrcnn_mask_loss: 0.1194 - val_loss: 1.7661 - val_rpn_class_loss: 0.1477 - val_rpn_bbox_loss: 1.0260 - val_mrcnn_class_loss: 0.1253 - val_mrcnn_bbox_loss: 0.2167 - val_mrcnn_mask_loss: 0.2503\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 246s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.8575 - rpn_class_loss: 0.0546 - rpn_bbox_loss: 0.5588 - mrcnn_class_loss: 0.0388 - mrcnn_bbox_loss: 0.1088 - mrcnn_mask_loss: 0.0966 - val_loss: 1.1914 - val_rpn_class_loss: 0.0618 - val_rpn_bbox_loss: 0.5067 - val_mrcnn_class_loss: 0.1536 - val_mrcnn_bbox_loss: 0.1440 - val_mrcnn_mask_loss: 0.3252\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 261s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.7507 - rpn_class_loss: 0.0263 - rpn_bbox_loss: 0.4624 - mrcnn_class_loss: 0.0317 - mrcnn_bbox_loss: 0.1111 - mrcnn_mask_loss: 0.1191 - val_loss: 0.9926 - val_rpn_class_loss: 0.0367 - val_rpn_bbox_loss: 0.4611 - val_mrcnn_class_loss: 0.0260 - val_mrcnn_bbox_loss: 0.1880 - val_mrcnn_mask_loss: 0.2808\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 241s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.6686 - rpn_class_loss: 0.0339 - rpn_bbox_loss: 0.3758 - mrcnn_class_loss: 0.0245 - mrcnn_bbox_loss: 0.0998 - mrcnn_mask_loss: 0.1347 - val_loss: 1.1500 - val_rpn_class_loss: 0.0437 - val_rpn_bbox_loss: 0.5794 - val_mrcnn_class_loss: 0.1131 - val_mrcnn_bbox_loss: 0.1223 - val_mrcnn_mask_loss: 0.2916\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 235s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.6596 - rpn_class_loss: 0.0247 - rpn_bbox_loss: 0.4173 - mrcnn_class_loss: 0.0208 - mrcnn_bbox_loss: 0.0943 - mrcnn_mask_loss: 0.1025 - val_loss: 0.9305 - val_rpn_class_loss: 0.0348 - val_rpn_bbox_loss: 0.3230 - val_mrcnn_class_loss: 0.0947 - val_mrcnn_bbox_loss: 0.1790 - val_mrcnn_mask_loss: 0.2989\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 20. LR=0.0002\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 307s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.3412 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.1658 - mrcnn_class_loss: 0.0148 - mrcnn_bbox_loss: 0.0574 - mrcnn_mask_loss: 0.0883 - val_loss: 0.7141 - val_rpn_class_loss: 0.0233 - val_rpn_bbox_loss: 0.2517 - val_mrcnn_class_loss: 0.0788 - val_mrcnn_bbox_loss: 0.0842 - val_mrcnn_mask_loss: 0.2760\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 238s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.3518 - rpn_class_loss: 0.0138 - rpn_bbox_loss: 0.1516 - mrcnn_class_loss: 0.0167 - mrcnn_bbox_loss: 0.0555 - mrcnn_mask_loss: 0.1143 - val_loss: 0.5238 - val_rpn_class_loss: 0.0172 - val_rpn_bbox_loss: 0.2130 - val_mrcnn_class_loss: 0.0444 - val_mrcnn_bbox_loss: 0.0677 - val_mrcnn_mask_loss: 0.1814\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 242s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2760 - rpn_class_loss: 0.0118 - rpn_bbox_loss: 0.1254 - mrcnn_class_loss: 0.0124 - mrcnn_bbox_loss: 0.0378 - mrcnn_mask_loss: 0.0886 - val_loss: 0.5066 - val_rpn_class_loss: 0.0145 - val_rpn_bbox_loss: 0.1337 - val_mrcnn_class_loss: 0.0676 - val_mrcnn_bbox_loss: 0.0713 - val_mrcnn_mask_loss: 0.2193\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 258s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2559 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.0970 - mrcnn_class_loss: 0.0130 - mrcnn_bbox_loss: 0.0410 - mrcnn_mask_loss: 0.0949 - val_loss: 0.6792 - val_rpn_class_loss: 0.0204 - val_rpn_bbox_loss: 0.1758 - val_mrcnn_class_loss: 0.0971 - val_mrcnn_bbox_loss: 0.0895 - val_mrcnn_mask_loss: 0.2964\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 254s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.3327 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.1442 - mrcnn_class_loss: 0.0085 - mrcnn_bbox_loss: 0.0693 - mrcnn_mask_loss: 0.1006 - val_loss: 0.8141 - val_rpn_class_loss: 0.0188 - val_rpn_bbox_loss: 0.2083 - val_mrcnn_class_loss: 0.1228 - val_mrcnn_bbox_loss: 0.1191 - val_mrcnn_mask_loss: 0.3451\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 255s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2558 - rpn_class_loss: 0.0108 - rpn_bbox_loss: 0.0889 - mrcnn_class_loss: 0.0116 - mrcnn_bbox_loss: 0.0496 - mrcnn_mask_loss: 0.0948 - val_loss: 0.6979 - val_rpn_class_loss: 0.0261 - val_rpn_bbox_loss: 0.2028 - val_mrcnn_class_loss: 0.1263 - val_mrcnn_bbox_loss: 0.0927 - val_mrcnn_mask_loss: 0.2500\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 250s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2362 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.0955 - mrcnn_class_loss: 0.0117 - mrcnn_bbox_loss: 0.0338 - mrcnn_mask_loss: 0.0856 - val_loss: 0.6278 - val_rpn_class_loss: 0.0171 - val_rpn_bbox_loss: 0.1958 - val_mrcnn_class_loss: 0.0867 - val_mrcnn_bbox_loss: 0.0836 - val_mrcnn_mask_loss: 0.2446\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 263s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2006 - rpn_class_loss: 0.0094 - rpn_bbox_loss: 0.0765 - mrcnn_class_loss: 0.0099 - mrcnn_bbox_loss: 0.0301 - mrcnn_mask_loss: 0.0747 - val_loss: 0.4769 - val_rpn_class_loss: 0.0168 - val_rpn_bbox_loss: 0.1531 - val_mrcnn_class_loss: 0.0505 - val_mrcnn_bbox_loss: 0.0603 - val_mrcnn_mask_loss: 0.1963\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 264s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2077 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.0720 - mrcnn_class_loss: 0.0119 - mrcnn_bbox_loss: 0.0321 - mrcnn_mask_loss: 0.0814 - val_loss: 0.4630 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 0.1107 - val_mrcnn_class_loss: 0.0644 - val_mrcnn_bbox_loss: 0.0570 - val_mrcnn_mask_loss: 0.2174\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 253s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.3156 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.1253 - mrcnn_class_loss: 0.0143 - mrcnn_bbox_loss: 0.0666 - mrcnn_mask_loss: 0.1018 - val_loss: 0.5217 - val_rpn_class_loss: 0.0185 - val_rpn_bbox_loss: 0.1623 - val_mrcnn_class_loss: 0.0727 - val_mrcnn_bbox_loss: 0.0591 - val_mrcnn_mask_loss: 0.2090\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 248s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2334 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.0996 - mrcnn_class_loss: 0.0089 - mrcnn_bbox_loss: 0.0346 - mrcnn_mask_loss: 0.0805 - val_loss: 0.7873 - val_rpn_class_loss: 0.0177 - val_rpn_bbox_loss: 0.2665 - val_mrcnn_class_loss: 0.0771 - val_mrcnn_bbox_loss: 0.1364 - val_mrcnn_mask_loss: 0.2895\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 264s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2291 - rpn_class_loss: 0.0084 - rpn_bbox_loss: 0.0980 - mrcnn_class_loss: 0.0099 - mrcnn_bbox_loss: 0.0300 - mrcnn_mask_loss: 0.0827 - val_loss: 0.5356 - val_rpn_class_loss: 0.0147 - val_rpn_bbox_loss: 0.1686 - val_mrcnn_class_loss: 0.0727 - val_mrcnn_bbox_loss: 0.0743 - val_mrcnn_mask_loss: 0.2053\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 273s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2117 - rpn_class_loss: 0.0068 - rpn_bbox_loss: 0.0738 - mrcnn_class_loss: 0.0106 - mrcnn_bbox_loss: 0.0360 - mrcnn_mask_loss: 0.0846 - val_loss: 0.5692 - val_rpn_class_loss: 0.0157 - val_rpn_bbox_loss: 0.2014 - val_mrcnn_class_loss: 0.0867 - val_mrcnn_bbox_loss: 0.0528 - val_mrcnn_mask_loss: 0.2126\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 273s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2656 - rpn_class_loss: 0.0087 - rpn_bbox_loss: 0.1237 - mrcnn_class_loss: 0.0107 - mrcnn_bbox_loss: 0.0402 - mrcnn_mask_loss: 0.0824 - val_loss: 0.4753 - val_rpn_class_loss: 0.0201 - val_rpn_bbox_loss: 0.2106 - val_mrcnn_class_loss: 0.0111 - val_mrcnn_bbox_loss: 0.0854 - val_mrcnn_mask_loss: 0.1482\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 277s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2380 - rpn_class_loss: 0.0081 - rpn_bbox_loss: 0.0879 - mrcnn_class_loss: 0.0093 - mrcnn_bbox_loss: 0.0417 - mrcnn_mask_loss: 0.0911 - val_loss: 0.5979 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.1802 - val_mrcnn_class_loss: 0.0262 - val_mrcnn_bbox_loss: 0.1650 - val_mrcnn_mask_loss: 0.2145\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 284s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1899 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.0715 - mrcnn_class_loss: 0.0073 - mrcnn_bbox_loss: 0.0285 - mrcnn_mask_loss: 0.0761 - val_loss: 0.5501 - val_rpn_class_loss: 0.0145 - val_rpn_bbox_loss: 0.1470 - val_mrcnn_class_loss: 0.0487 - val_mrcnn_bbox_loss: 0.1291 - val_mrcnn_mask_loss: 0.2108\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 292s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1462 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.0564 - mrcnn_class_loss: 0.0090 - mrcnn_bbox_loss: 0.0151 - mrcnn_mask_loss: 0.0599 - val_loss: 0.8785 - val_rpn_class_loss: 0.0150 - val_rpn_bbox_loss: 0.1220 - val_mrcnn_class_loss: 0.2448 - val_mrcnn_bbox_loss: 0.0986 - val_mrcnn_mask_loss: 0.3980\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 289s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2102 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.0647 - mrcnn_class_loss: 0.0107 - mrcnn_bbox_loss: 0.0430 - mrcnn_mask_loss: 0.0852 - val_loss: 0.4664 - val_rpn_class_loss: 0.0238 - val_rpn_bbox_loss: 0.1944 - val_mrcnn_class_loss: 0.0669 - val_mrcnn_bbox_loss: 0.0325 - val_mrcnn_mask_loss: 0.1489\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 274s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2322 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.1096 - mrcnn_class_loss: 0.0076 - mrcnn_bbox_loss: 0.0343 - mrcnn_mask_loss: 0.0737 - val_loss: 0.6073 - val_rpn_class_loss: 0.0143 - val_rpn_bbox_loss: 0.1689 - val_mrcnn_class_loss: 0.0880 - val_mrcnn_bbox_loss: 0.0715 - val_mrcnn_mask_loss: 0.2646\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 300s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2572 - rpn_class_loss: 0.0081 - rpn_bbox_loss: 0.1410 - mrcnn_class_loss: 0.0095 - mrcnn_bbox_loss: 0.0265 - mrcnn_mask_loss: 0.0721 - val_loss: 0.5159 - val_rpn_class_loss: 0.0110 - val_rpn_bbox_loss: 0.1020 - val_mrcnn_class_loss: 0.0742 - val_mrcnn_bbox_loss: 0.0730 - val_mrcnn_mask_loss: 0.2558\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/5,\n",
    "            epochs=40,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 40. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 313s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2100 - rpn_class_loss: 0.0074 - rpn_bbox_loss: 0.0751 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.0373 - mrcnn_mask_loss: 0.0817 - val_loss: 0.7133 - val_rpn_class_loss: 0.0154 - val_rpn_bbox_loss: 0.1107 - val_mrcnn_class_loss: 0.1266 - val_mrcnn_bbox_loss: 0.1035 - val_mrcnn_mask_loss: 0.3572\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 252s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2008 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.0552 - mrcnn_class_loss: 0.0076 - mrcnn_bbox_loss: 0.0397 - mrcnn_mask_loss: 0.0917 - val_loss: 0.4010 - val_rpn_class_loss: 0.0124 - val_rpn_bbox_loss: 0.1150 - val_mrcnn_class_loss: 0.0489 - val_mrcnn_bbox_loss: 0.0558 - val_mrcnn_mask_loss: 0.1688\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 252s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1548 - rpn_class_loss: 0.0056 - rpn_bbox_loss: 0.0562 - mrcnn_class_loss: 0.0058 - mrcnn_bbox_loss: 0.0198 - mrcnn_mask_loss: 0.0673 - val_loss: 0.4154 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.0739 - val_mrcnn_class_loss: 0.0743 - val_mrcnn_bbox_loss: 0.0513 - val_mrcnn_mask_loss: 0.2057\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 302s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1623 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0496 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.0226 - mrcnn_mask_loss: 0.0775 - val_loss: 0.4730 - val_rpn_class_loss: 0.0148 - val_rpn_bbox_loss: 0.1630 - val_mrcnn_class_loss: 0.0663 - val_mrcnn_bbox_loss: 0.0586 - val_mrcnn_mask_loss: 0.1703\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 248s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1855 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.0520 - mrcnn_class_loss: 0.0102 - mrcnn_bbox_loss: 0.0352 - mrcnn_mask_loss: 0.0818 - val_loss: 0.6330 - val_rpn_class_loss: 0.0163 - val_rpn_bbox_loss: 0.1476 - val_mrcnn_class_loss: 0.1038 - val_mrcnn_bbox_loss: 0.0959 - val_mrcnn_mask_loss: 0.2695\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 242s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1774 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.0516 - mrcnn_class_loss: 0.0078 - mrcnn_bbox_loss: 0.0317 - mrcnn_mask_loss: 0.0806 - val_loss: 0.5281 - val_rpn_class_loss: 0.0133 - val_rpn_bbox_loss: 0.1384 - val_mrcnn_class_loss: 0.0802 - val_mrcnn_bbox_loss: 0.0631 - val_mrcnn_mask_loss: 0.2331\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 238s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1799 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.0639 - mrcnn_class_loss: 0.0076 - mrcnn_bbox_loss: 0.0266 - mrcnn_mask_loss: 0.0755 - val_loss: 0.4464 - val_rpn_class_loss: 0.0124 - val_rpn_bbox_loss: 0.1330 - val_mrcnn_class_loss: 0.0632 - val_mrcnn_bbox_loss: 0.0575 - val_mrcnn_mask_loss: 0.1803\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 235s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1402 - rpn_class_loss: 0.0048 - rpn_bbox_loss: 0.0505 - mrcnn_class_loss: 0.0079 - mrcnn_bbox_loss: 0.0128 - mrcnn_mask_loss: 0.0643 - val_loss: 1.0227 - val_rpn_class_loss: 0.0234 - val_rpn_bbox_loss: 0.2019 - val_mrcnn_class_loss: 0.2207 - val_mrcnn_bbox_loss: 0.1400 - val_mrcnn_mask_loss: 0.4368\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 237s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1351 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.0404 - mrcnn_class_loss: 0.0071 - mrcnn_bbox_loss: 0.0166 - mrcnn_mask_loss: 0.0656 - val_loss: 0.6798 - val_rpn_class_loss: 0.0170 - val_rpn_bbox_loss: 0.1817 - val_mrcnn_class_loss: 0.1201 - val_mrcnn_bbox_loss: 0.0882 - val_mrcnn_mask_loss: 0.2727\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 237s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1320 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.0335 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.0177 - mrcnn_mask_loss: 0.0680 - val_loss: 0.4068 - val_rpn_class_loss: 0.0108 - val_rpn_bbox_loss: 0.0935 - val_mrcnn_class_loss: 0.0681 - val_mrcnn_bbox_loss: 0.0515 - val_mrcnn_mask_loss: 0.1830\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/10,\n",
    "            epochs=50,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 50. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Home\\Files\\AI_suidies\\Project\\welding\\logs\\welding20220531T1122\\mask_rcnn_welding_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 303s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1623 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.0500 - mrcnn_class_loss: 0.0079 - mrcnn_bbox_loss: 0.0241 - mrcnn_mask_loss: 0.0755 - val_loss: 0.7460 - val_rpn_class_loss: 0.0163 - val_rpn_bbox_loss: 0.1738 - val_mrcnn_class_loss: 0.1399 - val_mrcnn_bbox_loss: 0.0924 - val_mrcnn_mask_loss: 0.3237\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 243s 2s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1567 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.0522 - mrcnn_class_loss: 0.0075 - mrcnn_bbox_loss: 0.0194 - mrcnn_mask_loss: 0.0723 - val_loss: 0.9739 - val_rpn_class_loss: 0.0162 - val_rpn_bbox_loss: 0.1165 - val_mrcnn_class_loss: 0.2661 - val_mrcnn_bbox_loss: 0.1190 - val_mrcnn_mask_loss: 0.4560\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 312s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1567 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0336 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.0291 - mrcnn_mask_loss: 0.0814 - val_loss: 0.7287 - val_rpn_class_loss: 0.0139 - val_rpn_bbox_loss: 0.1565 - val_mrcnn_class_loss: 0.1717 - val_mrcnn_bbox_loss: 0.0850 - val_mrcnn_mask_loss: 0.3016\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 364s 4s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1561 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.0486 - mrcnn_class_loss: 0.0065 - mrcnn_bbox_loss: 0.0202 - mrcnn_mask_loss: 0.0751 - val_loss: 0.6822 - val_rpn_class_loss: 0.0194 - val_rpn_bbox_loss: 0.1779 - val_mrcnn_class_loss: 0.1339 - val_mrcnn_bbox_loss: 0.0766 - val_mrcnn_mask_loss: 0.2745\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 457s 5s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1325 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.0353 - mrcnn_class_loss: 0.0069 - mrcnn_bbox_loss: 0.0159 - mrcnn_mask_loss: 0.0699 - val_loss: 0.5210 - val_rpn_class_loss: 0.0148 - val_rpn_bbox_loss: 0.1651 - val_mrcnn_class_loss: 0.0685 - val_mrcnn_bbox_loss: 0.0690 - val_mrcnn_mask_loss: 0.2035\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 453s 5s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1674 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.0584 - mrcnn_class_loss: 0.0057 - mrcnn_bbox_loss: 0.0263 - mrcnn_mask_loss: 0.0711 - val_loss: 0.5751 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.1124 - val_mrcnn_class_loss: 0.1063 - val_mrcnn_bbox_loss: 0.0997 - val_mrcnn_mask_loss: 0.2444\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 363s 4s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1651 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.0449 - mrcnn_class_loss: 0.0087 - mrcnn_bbox_loss: 0.0262 - mrcnn_mask_loss: 0.0789 - val_loss: 0.4809 - val_rpn_class_loss: 0.0118 - val_rpn_bbox_loss: 0.1699 - val_mrcnn_class_loss: 0.0717 - val_mrcnn_bbox_loss: 0.0504 - val_mrcnn_mask_loss: 0.1771\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 330s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1828 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.0553 - mrcnn_class_loss: 0.0074 - mrcnn_bbox_loss: 0.0308 - mrcnn_mask_loss: 0.0829 - val_loss: 0.5359 - val_rpn_class_loss: 0.0131 - val_rpn_bbox_loss: 0.1324 - val_mrcnn_class_loss: 0.1028 - val_mrcnn_bbox_loss: 0.0609 - val_mrcnn_mask_loss: 0.2267\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 329s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.1893 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0629 - mrcnn_class_loss: 0.0103 - mrcnn_bbox_loss: 0.0311 - mrcnn_mask_loss: 0.0790 - val_loss: 0.3325 - val_rpn_class_loss: 0.0099 - val_rpn_bbox_loss: 0.0976 - val_mrcnn_class_loss: 0.0444 - val_mrcnn_bbox_loss: 0.0370 - val_mrcnn_mask_loss: 0.1436\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 322s 3s/step - batch: 49.5000 - size: 1.0000 - loss: 0.2309 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.0784 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.0481 - mrcnn_mask_loss: 0.0894 - val_loss: 0.6095 - val_rpn_class_loss: 0.0204 - val_rpn_bbox_loss: 0.1880 - val_mrcnn_class_loss: 0.1013 - val_mrcnn_bbox_loss: 0.0754 - val_mrcnn_mask_loss: 0.2243\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/10,\n",
    "            epochs=60,\n",
    "            layers=\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
